# ä¸‡å­—é•¿æ–‡å¸¦ä½ 0-1æ­å»ºå’Œè®­ç»ƒç¥ç»ç½‘ç»œ

A repository for learning PyTorch concepts and implementing various examples.

## torchvision ä»‹ç»ä¸ä½¿ç”¨æŒ‡å—

### 1. torchvision åŸºæœ¬æ¦‚å¿µ

`Torchvision` æ˜¯ `PyTorch` çš„ä¸€ä¸ªé‡è¦æ‰©å±•åº“ï¼Œä¸“é—¨ç”¨äºè®¡ç®—æœºè§†è§‰ä»»åŠ¡ï¼Œæä¾›äº†ä¸°å¯Œçš„å·¥å…·å’Œèµ„æºï¼Œä¸»è¦åŒ…æ‹¬ä»¥ä¸‹æ ¸å¿ƒç»„ä»¶ï¼š

å®˜æ–¹æ–‡æ¡£ï¼š[Torchvision å®˜æ–¹æ–‡æ¡£](https://docs.pytorch.org/vision/stable/index.html)

- **torchvision.datasets**: æä¾›å¸¸ç”¨çš„è®¡ç®—æœºè§†è§‰æ•°æ®é›†ä¸‹è½½å’ŒåŠ è½½åŠŸèƒ½ï¼Œå¦‚MNISTã€COCOã€VOCç­‰
- **torchvision.io**: æä¾›è§†é¢‘è¯»å†™ã€å›¾åƒè¯»å†™å’Œç¼–ç è§£ç åŠŸèƒ½ï¼Œæ”¯æŒJPEGã€PNGç­‰æ ¼å¼
- **torchvision.models**: æä¾›é¢„è®­ç»ƒçš„æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œå¦‚AlexNetã€VGGã€ResNetã€Inceptionç­‰
- **torchvision.ops**: æä¾›è®¡ç®—æœºè§†è§‰ç›¸å…³çš„æ“ä½œå‡½æ•°
- **torchvision.transforms**: æä¾›å›¾åƒé¢„å¤„ç†å’Œæ•°æ®å¢å¼ºçš„åŠŸèƒ½
- **torchvision.utils**: æä¾›ä¸€äº›å®ç”¨å·¥å…·å‡½æ•°

#### 1.1. TensorBoard å¯è§†åŒ–å›¾åƒå˜æ¢

`TensorBoard` æ˜¯ä¸€ä¸ªå¼ºå¤§çš„å¯è§†åŒ–å·¥å…·ï¼Œå¯ä»¥ç”¨äºå±•ç¤ºå›¾åƒå˜æ¢çš„è¿‡ç¨‹ã€‚åœ¨åç»­çš„æ·±åº¦å­¦ä¹ ä»£ç ä¸­ï¼Œæˆ‘ä»¬ä¼šé¢‘ç¹çš„ä½¿ç”¨åˆ°è¿™ä¸ªå·¥å…·ï¼Œæ¥è§‚å¯Ÿå›¾åƒçš„å„ç§å˜æ¢è¿‡ç¨‹ã€‚

åœ¨ç¤ºä¾‹ä»£ç ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨ `TensorBoard` æ¥å¯è§†åŒ–å„ç§ `Transforms` å¯¹å›¾åƒçš„å½±å“ã€‚

**ä½¿ç”¨æ–¹æ³•**

1. å®‰è£… `TensorBoard`ï¼š`pip install tensorboard`
2. åœ¨ä»£ç ä¸­åˆ›å»º `SummaryWriter`ï¼š
   ```python
   from torch.utils.tensorboard import SummaryWriter
   writer = SummaryWriter("logs")
   ```
3. å†™å…¥å›¾åƒæ•°æ®ï¼š
   ```python
   writer.add_image("Image Title", image_tensor, global_step)
   ```
4. è¿è¡ŒTensorBoardï¼š`tensorboard --logdir=logs`
5. åœ¨æµè§ˆå™¨ä¸­è®¿é—®TensorBoardç•Œé¢ï¼ˆé€šå¸¸æ˜¯http://localhost:6006ï¼‰

#### 1.2. Transforms çš„åŸºæœ¬ä½¿ç”¨

`Transforms` æ˜¯ `torchvision` ä¸­ç”¨äºå›¾åƒé¢„å¤„ç†å’Œæ•°æ®å¢å¼ºçš„é‡è¦æ¨¡å—ï¼Œå¯ä»¥å¯¹å›¾åƒè¿›è¡Œå„ç§å˜æ¢æ“ä½œã€‚

ä»¥ä¸‹æ˜¯ä¸€äº›å¸¸ç”¨çš„ `Transforms`ï¼š

#### 1.3. å¸¸ç”¨çš„ `Transforms` æ“ä½œ

- **ToTensor()**: å°† PIL å›¾åƒæˆ– numpy æ•°ç»„è½¬æ¢ä¸º Tensor æ ¼å¼ã€‚è¿™ä¸ªæ“ä½œæˆ‘ä»¬éå¸¸å¸¸ç”¨ï¼Œå› ä¸ºå®ƒå¯ä»¥å°†å›¾åƒè½¬æ¢ä¸º PyTorch ä¸­çš„å¼ é‡æ ¼å¼ï¼Œæ–¹ä¾¿åç»­çš„æ·±åº¦å­¦ä¹ æ¨¡å‹å¤„ç†ã€‚

- **Normalize(mean, std)**: å¯¹Tensorå›¾åƒè¿›è¡Œæ ‡å‡†åŒ–ï¼ˆå½’ä¸€åŒ–ï¼‰ã€‚æ‰€è°“å½’ä¸€åŒ–æ˜¯æŒ‡å°†å›¾åƒçš„åƒç´ å€¼ä»åŸå§‹èŒƒå›´ï¼ˆé€šå¸¸æ˜¯0åˆ°255ï¼‰æ˜ å°„åˆ°æ ‡å‡†èŒƒå›´ï¼ˆé€šå¸¸æ˜¯-1åˆ°1æˆ–0åˆ°1ï¼‰ï¼Œä»¥æé«˜æ¨¡å‹çš„è®­ç»ƒæ•ˆæœå’Œæ”¶æ•›é€Ÿåº¦ã€‚

`output[channel] = (input[channel] - mean[channel]) / std[channel]`

è¿™æ ·çš„è¯å¯ä»¥ä½¿å¾—å›¾ç‰‡é¢œè‰²åˆ†å¸ƒæ›´åŠ å‡åŒ€ï¼Œæé«˜æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ï¼Œæœ‰åŠ©äºæ¨¡å‹çš„è®­ç»ƒã€‚

- **Resize(size)**: è°ƒæ•´å›¾åƒå°ºå¯¸ã€‚è¿™ä¸ªæ“ä½œå¯ä»¥å°†å›¾åƒè°ƒæ•´ä¸ºæŒ‡å®šçš„å°ºå¯¸ï¼Œé€šå¸¸ç”¨äºå›¾åƒé¢„å¤„ç†æˆ–æ¨¡å‹è¾“å…¥ã€‚

---

ä¸‹é¢è¿˜æœ‰ä¸€äº›æ“ä½œ

- **CenterCrop(size)**: ä»å›¾åƒä¸­å¿ƒè£å‰ªæŒ‡å®šå°ºå¯¸
- **RandomCrop(size)**: éšæœºè£å‰ªæŒ‡å®šå°ºå¯¸
- **RandomHorizontalFlip(p=0.5)**: éšæœºæ°´å¹³ç¿»è½¬å›¾åƒ
- **RandomVerticalFlip(p=0.5)**: éšæœºå‚ç›´ç¿»è½¬å›¾åƒ
- **ColorJitter(brightness, contrast, saturation, hue)**: éšæœºè°ƒæ•´å›¾åƒçš„äº®åº¦ã€å¯¹æ¯”åº¦ã€é¥±å’Œåº¦å’Œè‰²è°ƒ


å¯ä»¥ä½¿ç”¨`transforms.Compose()`å°†å¤šä¸ªTransformsç»„åˆåœ¨ä¸€èµ·ï¼Œå½¢æˆä¸€ä¸ªå˜æ¢åºåˆ—ï¼š

```python
composed_transform = transforms.Compose([
    transforms.Resize((256, 256)),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])
```

è¿™é‡Œä»‹ç»äº†è¿™ä¹ˆå¤šæ“ä½œï¼Œå¯ä»¥ä½¿ç”¨ä»¥ä¸‹ä»£ç äº²è‡ªè·‘ä¸€ä¸‹ï¼Œçœ‹çœ‹æ•ˆæœï¼š
```python
import torch
import torchvision
from torchvision import transforms
from PIL import Image
import matplotlib.pyplot as plt
from torch.utils.tensorboard import SummaryWriter
import os

def main():
    # åŠ è½½å›¾ç‰‡
    img_path = "demo1.png"
    
    img = Image.open(img_path)
    # å°†RGBAå›¾åƒè½¬æ¢ä¸ºRGBå›¾åƒ
    if img.mode == 'RGBA':
        img = img.convert('RGB')
    
    # åˆ›å»ºå„ç§Transforms
    transform_list = [
        ("ToTensor", transforms.ToTensor()),
        ("Resize", transforms.Resize((256, 256))),
        ("CenterCrop", transforms.CenterCrop(200)),
        ("RandomCrop", transforms.RandomCrop(200)),
        ("RandomHorizontalFlip", transforms.RandomHorizontalFlip(p=1)),
        ("RandomVerticalFlip", transforms.RandomVerticalFlip(p=1)),
        ("ColorJitter", transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0.5)),
        ("Normalize", transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])]))
    ]
    
    # åˆ›å»ºSummaryWriter
    writer = SummaryWriter("logs")
    
    # å†™å…¥åŸå§‹å›¾ç‰‡
    img_tensor = transforms.ToTensor()(img)
    writer.add_image("Original Image", img_tensor, 0)
    
    # åº”ç”¨å„ç§å˜æ¢å¹¶å†™å…¥TensorBoard
    for i, (transform_name, transform) in enumerate(transform_list):
        if transform_name == "Normalize":
            # Normalizeéœ€è¦å…ˆè½¬æ¢ä¸ºTensor
            transformed_img = transform(img)
        else:
            transformed_img = transform(img)
            # å¦‚æœä¸æ˜¯Tensorï¼Œè½¬æ¢ä¸ºTensorä»¥ä¾¿å†™å…¥TensorBoard
            if not isinstance(transformed_img, torch.Tensor):
                transformed_img = transforms.ToTensor()(transformed_img)
        
        writer.add_image(f"{transform_name}", transformed_img, i+1)
        print(f"åº”ç”¨ {transform_name} å˜æ¢åçš„å›¾ç‰‡å½¢çŠ¶: {transformed_img.shape}")
    
    
    # å…³é—­SummaryWriter
    writer.close()

if __name__ == "__main__":
    main()
```



#### 1.4. Dataset æ•°æ®é›†çš„ä½¿ç”¨

`Dataset` æ˜¯ `torchvision` ä¸­ç”¨äºåŠ è½½å’Œå¤„ç†æ•°æ®é›†çš„é‡è¦æ¨¡å—ã€‚å®ƒå¯ä»¥å¸®åŠ©æˆ‘ä»¬æ–¹ä¾¿åœ°åŠ è½½å›¾åƒæ•°æ®é›†ã€æ ‡æ³¨æ•°æ®é›†ç­‰ã€‚

`torchvision.datasets` æ¨¡å—æä¾›äº†è®¸å¤šå¸¸ç”¨çš„æ•°æ®é›†åŠ è½½å‡½æ•°ï¼Œä»¥ä¸‹æ˜¯å…¶ä¸­çš„ä¸€äº›ï¼š

- **CIFAR10**: åŠ è½½ CIFAR-10 æ•°æ®é›†ã€‚CIFAR-10 æ˜¯ä¸€ä¸ªåŒ…å« 60000 å¼  32x32 å½©è‰²å›¾åƒçš„æ•°æ®é›†ï¼Œåˆ†ä¸º 10 ä¸ªç±»åˆ«ã€‚

- **CIFAR100**: åŠ è½½ CIFAR-100 æ•°æ®é›†ã€‚CIFAR-100 æ˜¯ä¸€ä¸ªåŒ…å« 60000 å¼  32x32 å½©è‰²å›¾åƒçš„æ•°æ®é›†ï¼Œåˆ†ä¸º 100 ä¸ªç±»åˆ«ã€‚

- **Country211**ï¼šè¯¥æ•°æ®é›†æ˜¯é€šè¿‡ä» YFCC100m æ•°æ®é›†ä¸­ç­›é€‰å‡ºå…·æœ‰ä¸ ISO-3166 å›½å®¶ä»£ç å¯¹åº”çš„ GPS åæ ‡çš„å›¾åƒæ„å»ºè€Œæˆçš„ã€‚ä¸ºäº†å®ç°æ•°æ®é›†çš„å¹³è¡¡ï¼Œæ¯ä¸ªå›½å®¶ä¼šæŠ½å– 150 å¼ è®­ç»ƒå›¾åƒã€50 å¼ éªŒè¯å›¾åƒå’Œ 100 å¼ æµ‹è¯•å›¾åƒã€‚

åŠ è½½æ–¹å¼ä¹Ÿå¾ˆç®€å•ï¼š

```python
from torchvision.datasets import Country211

# åŠ è½½è®­ç»ƒé›†
train_dataset = Country211(root='./data', Train=True, download=True)
```

#### 1.5. dataLoader æ•°æ®åŠ è½½å™¨

`DataLoader` æ˜¯ `torch.utils.data` æ¨¡å—ä¸­çš„ä¸€ä¸ªç±»ï¼Œç”¨äºå°†æ•°æ®é›†ï¼ˆ`Dataset`ï¼‰å°è£…ä¸ºä¸€ä¸ªå¯è¿­ä»£çš„å¯¹è±¡ï¼Œä»¥ä¾¿äºåœ¨è®­ç»ƒæ¨¡å‹æ—¶æ‰¹é‡åŠ è½½æ•°æ®ã€‚

ä¸‹é¢æ˜¯ä¸€ä¸ªç®€å•çš„ç¤ºä¾‹ï¼Œå±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨ `DataLoader` åŠ è½½ CIFAR-10 æ•°æ®é›†ï¼š
- `batch_size=64`ï¼šæ¯ä¸ªæ‰¹æ¬¡åŒ…å« 64 å¼ å›¾åƒã€‚
- `shuffle=True`ï¼šåœ¨æ¯ä¸ª epoch å¼€å§‹æ—¶ï¼Œéšæœºæ‰“ä¹±æ•°æ®é›†çš„é¡ºåºã€‚

```python
from torch.utils.tensorboard import SummaryWriter
from torchvision import transforms, datasets
from torch.utils.data import DataLoader


def main():
    # åŠ è½½è®­ç»ƒé›†
    train_dataset = datasets.CIFAR10(
        root="./dataset", train=False, download=True, transform=transforms.ToTensor()
    )
    writer = SummaryWriter("logs")
    dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)
    step = 0
    for batch in dataloader:
        images, labels = batch
        writer.add_images("Batch Images2", images, step)
        print(step)
        step += 1
    writer.close()


if __name__ == "__main__":
    main()

```


### 2. ç¥ç»ç½‘ç»œ

#### 2.1. å·ç§¯å±‚

å·ç§¯å±‚æ˜¯ç¥ç»ç½‘ç»œä¸­æœ€åŸºæœ¬çš„å±‚ä¹‹ä¸€ï¼Œç”¨äºæå–å›¾åƒçš„ç‰¹å¾ã€‚å®ƒé€šè¿‡å·ç§¯æ“ä½œå°†è¾“å…¥å›¾åƒä¸ä¸€ç»„å¯å­¦ä¹ çš„å·ç§¯æ ¸è¿›è¡Œå·ç§¯ï¼Œä»è€Œç”Ÿæˆç‰¹å¾å›¾ã€‚

æˆ‘ä»¬å¯ä»¥é€šè¿‡ `torch.nn` æ¥å®ç°ä¸€ä¸ªç¥ç»ç½‘ç»œ

```python
import torch
import torch.nn as nn

class SimpleConv2d(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = nn.Conv2d(
            in_channels=3, out_channels=6, kernel_size=3, stride=1, padding=1
        )

    def forward(self, x):
        x = self.conv1(x)
        return x
```

##### 2.1.1 å·ç§¯å±‚è¾“å‡ºå°ºå¯¸è®¡ç®—

**ä¸ºä»€ä¹ˆ padding=1 æ—¶è¾“å‡ºå°ºå¯¸ä¿æŒ 32Ã—32ï¼Ÿ**

å½“ä½ è¿è¡Œä»£ç æ—¶ä¼šå‘ç°ï¼Œè¾“å…¥ CIFAR10 çš„ 32Ã—32 å›¾åƒç»è¿‡ `kernel_size=3, padding=1, stride=1` çš„å·ç§¯å±‚åï¼Œè¾“å‡ºä»ç„¶æ˜¯ 32Ã—32 å°ºå¯¸ã€‚è¿™æ˜¯é€šè¿‡ä»¥ä¸‹å…¬å¼è®¡ç®—çš„ï¼š

```
è¾“å‡ºå°ºå¯¸ = (è¾“å…¥å°ºå¯¸ - å·ç§¯æ ¸å¤§å° + 2Ã—padding) Ã· stride + 1
```

**å…·ä½“è®¡ç®—è¿‡ç¨‹ï¼š**
- è¾“å…¥å°ºå¯¸ (CIFAR10 å›¾åƒ)ï¼š32Ã—32
- å·ç§¯æ ¸å¤§å° (kernel_size)ï¼š3
- å¡«å…… (padding)ï¼š1
- æ­¥å¹… (stride)ï¼š1

ä»£å…¥å…¬å¼ï¼š
```
è¾“å‡ºé«˜åº¦ = (32 - 3 + 2Ã—1) Ã· 1 + 1 = (31) Ã· 1 + 1 = 32
è¾“å‡ºå®½åº¦ = (32 - 3 + 2Ã—1) Ã· 1 + 1 = (31) Ã· 1 + 1 = 32
```

##### 2.1.2 å·ç§¯è¿‡ç¨‹ç¤ºä¾‹

ä¸ºäº†æ›´ç›´è§‚åœ°ç†è§£å·ç§¯æ“ä½œï¼Œè®©æˆ‘ä»¬é€šè¿‡ä¸€ä¸ªç®€å•çš„ä¾‹å­æ¥æ¼”ç¤ºå·ç§¯è¿‡ç¨‹ã€‚

**è¾“å…¥ç‰¹å¾å›¾**ï¼ˆå•é€šé“ï¼Œ5Ã—5ï¼‰ï¼š
```
è¾“å…¥ç‰¹å¾å›¾ï¼š
1  2  3  0  1
4  5  6  1  0
7  8  9  2  1
0  1  2  3  4
3  2  1  0  5
```

**å·ç§¯æ ¸**ï¼ˆ3Ã—3ï¼Œå•è¾“å‡ºé€šé“ï¼‰ï¼š
```
å·ç§¯æ ¸ï¼š
1  0  -1
1  0  -1
1  0  -1
```

**å·ç§¯æ“ä½œæ­¥éª¤**ï¼ˆæ­¥é•¿=1ï¼Œæ— å¡«å……ï¼‰ï¼š

1. **ç¬¬ä¸€ä¸ªçª—å£**ï¼ˆå·¦ä¸Šè§’3Ã—3åŒºåŸŸï¼‰ï¼š
   ```
   è¾“å…¥åŒºåŸŸï¼š
   1  2  3
   4  5  6
   7  8  9
   
   ä¸å·ç§¯æ ¸ç›¸ä¹˜æ±‚å’Œï¼š
   (1Ã—1) + (2Ã—0) + (3Ã—-1) +
   (4Ã—1) + (5Ã—0) + (6Ã—-1) +
   (7Ã—1) + (8Ã—0) + (9Ã—-1)
   = 1 + 0 - 3 + 4 + 0 - 6 + 7 + 0 - 9 = -6
   ```

2. **ç¬¬äºŒä¸ªçª—å£**ï¼ˆå³ç§»ä¸€æ­¥ï¼‰ï¼š
   ```
   è¾“å…¥åŒºåŸŸï¼š
   2  3  0
   5  6  1
   8  9  2
   
   ä¸å·ç§¯æ ¸ç›¸ä¹˜æ±‚å’Œï¼š
   (2Ã—1) + (3Ã—0) + (0Ã—-1) +
   (5Ã—1) + (6Ã—0) + (1Ã—-1) +
   (8Ã—1) + (9Ã—0) + (2Ã—-1)
   = 2 + 0 + 0 + 5 + 0 - 1 + 8 + 0 - 2 = 12
   ```

3. **ç¬¬ä¸‰ä¸ªçª—å£**ï¼ˆç»§ç»­å³ç§»ä¸€æ­¥ï¼‰ï¼š
   ```
   è¾“å…¥åŒºåŸŸï¼š
   3  0  1
   6  1  0
   9  2  1
   
   ä¸å·ç§¯æ ¸ç›¸ä¹˜æ±‚å’Œï¼š
   (3Ã—1) + (0Ã—0) + (1Ã—-1) +
   (6Ã—1) + (1Ã—0) + (0Ã—-1) +
   (9Ã—1) + (2Ã—0) + (1Ã—-1)
   = 3 + 0 - 1 + 6 + 0 + 0 + 9 + 0 - 1 = 16
   ```

4. **åç»­çª—å£**ï¼š
   ç»§ç»­æŒ‰ç…§æ­¥é•¿=1å‘å³æ»‘åŠ¨ï¼Œå¤„ç†å®Œç¬¬ä¸€è¡Œåå‘ä¸‹æ»‘åŠ¨ä¸€è¡Œï¼Œé‡å¤ä¸Šè¿°è¿‡ç¨‹ã€‚

**æœ€ç»ˆè¾“å‡ºç‰¹å¾å›¾**ï¼ˆ3Ã—3ï¼‰ï¼š
```
è¾“å‡ºç‰¹å¾å›¾ï¼š
-6  12  16
-12  18  20
-21  15  14
```

**å¤šé€šé“å·ç§¯ç¤ºä¾‹**ï¼š

å½“è¾“å…¥æœ‰å¤šä¸ªé€šé“æ—¶ï¼Œæ¯ä¸ªé€šé“ä¼šæœ‰å¯¹åº”çš„å·ç§¯æ ¸ï¼Œæœ€ç»ˆç»“æœæ˜¯å„é€šé“å·ç§¯ç»“æœçš„æ€»å’Œã€‚

å‡è®¾è¾“å…¥æœ‰2ä¸ªé€šé“ï¼Œæ¯ä¸ªé€šé“æœ‰å¯¹åº”çš„3Ã—3å·ç§¯æ ¸ï¼š

**è¾“å…¥é€šé“1**ï¼š
```
1  2
3  4
```

**è¾“å…¥é€šé“2**ï¼š
```
5  6
7  8
```

**å·ç§¯æ ¸é€šé“1**ï¼š
```
1  0
0  1
```

**å·ç§¯æ ¸é€šé“2**ï¼š
```
0  1
1  0
```

**è®¡ç®—è¿‡ç¨‹**ï¼š
- é€šé“1å·ç§¯ç»“æœï¼š(1Ã—1)+(2Ã—0)+(3Ã—0)+(4Ã—1) = 1+0+0+4 = 5
- é€šé“2å·ç§¯ç»“æœï¼š(5Ã—0)+(6Ã—1)+(7Ã—1)+(8Ã—0) = 0+6+7+0 = 13
- æœ€ç»ˆè¾“å‡ºï¼š5 + 13 = 18

åœ¨æœ¬ç« èŠ‚ä¸€å¼€å§‹çš„ä¾‹å­ä¸­ï¼Œä¸€å…±ä¼šç”Ÿæˆ 6 ä¸ªå·ç§¯æ ¸è¿›è¡Œå·ç§¯æ“ä½œï¼Œæ¯ä¸ªå·ç§¯æ ¸çš„ç»“æ„æ˜¯ `(3, 3, 3)`ï¼Œå…¶å€¼æ˜¯éšæœºåˆå§‹åŒ–çš„ã€‚

#### 2.2. æœ€å¤§æ± åŒ–å±‚

æœ€å¤§æ± åŒ–ï¼ˆMax Poolingï¼‰æœ€å¤§æ± åŒ–æ˜¯å·ç§¯ç¥ç»ç½‘ç»œä¸­å¸¸ç”¨çš„æ“ä½œï¼Œå…·æœ‰ä»¥ä¸‹é‡è¦ä½œç”¨ï¼š

- ğŸ”¹ é™ç»´ï¼ˆDimensionality Reductionï¼‰
**æœ€å¤§æ± åŒ–å¯ä»¥å‡å°‘ç‰¹å¾å›¾çš„ç©ºé—´ç»´åº¦ï¼ˆé«˜åº¦å’Œå®½åº¦ï¼‰ï¼Œä¸èƒ½æ”¹å˜é€šé“æ•°**ï¼Œä»è€Œå‡å°‘åç»­å±‚çš„å‚æ•°æ•°é‡å’Œè®¡ç®—é‡ã€‚è¿™æœ‰åŠ©äºé™ä½æ¨¡å‹çš„å¤æ‚åº¦ï¼Œæé«˜è®­ç»ƒé€Ÿåº¦ã€‚

- ğŸ”¹ æå–ä¸»è¦ç‰¹å¾
æ± åŒ–çª—å£ä¼šé€‰æ‹©åŒºåŸŸå†…çš„æœ€å¤§å€¼ï¼Œè¿™ç›¸å½“äºä¿ç•™äº†è¯¥åŒºåŸŸå†…æœ€æ˜¾è‘—ã€æœ€å…³é”®çš„ç‰¹å¾ï¼Œä¸¢å¼ƒäº†æ¬¡è¦ä¿¡æ¯ã€‚è¿™æ ·å¯ä»¥ä½¿æ¨¡å‹æ›´åŠ å…³æ³¨é‡è¦ç‰¹å¾ã€‚

- ğŸ”¹ é˜²æ­¢è¿‡æ‹Ÿåˆ
é€šè¿‡å‡å°‘ç‰¹å¾æ•°é‡å’Œå¤æ‚åº¦ï¼Œæœ€å¤§æ± åŒ–æœ‰åŠ©äºé˜²æ­¢æ¨¡å‹å¯¹è®­ç»ƒæ•°æ®è¿‡åº¦æ‹Ÿåˆï¼Œæé«˜æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚

- ğŸ”¹ å¢å¼ºé²æ£’æ€§
æœ€å¤§æ± åŒ–å¯ä»¥è¿‡æ»¤æ‰ä¸€äº›å™ªå£°å’Œç»†èŠ‚ï¼Œä½¿æ¨¡å‹æ›´åŠ é²æ£’ã€‚

æœ€å¤§æ± åŒ–çš„æ“ä½œæ­¥éª¤è·Ÿå·ç§¯å¾ˆç›¸ä¼¼ï¼Œåªæ˜¯æ± åŒ–çª—å£åœ¨è¾“å…¥ä¸Šæ»‘åŠ¨ï¼Œæ¯æ¬¡å–çª—å£å†…çš„æœ€å¤§å€¼ä½œä¸ºè¾“å‡ºã€‚ä¸¾ä¸ªä¾‹å­ï¼š

å‡è®¾è¾“å…¥æ˜¯ä¸€ä¸ª 5x5 çš„ç‰¹å¾å›¾ï¼ˆä¸ºäº†ç®€å•èµ·è§ï¼Œæˆ‘ä»¬åªçœ‹ä¸€ä¸ªé€šé“ï¼‰ï¼š

```
è¾“å…¥ç‰¹å¾å›¾ï¼š
1  3  2  4  0
5  2  7  1  3
9  6  3  8  2
2  5  1  7  4
8  3  6  2  9
```

ä½¿ç”¨ 3x3 æœ€å¤§æ± åŒ–ï¼Œæ­¥é•¿ä¸º `1`ï¼Œå¤„ç†è¿‡ç¨‹å¦‚ä¸‹ï¼š

```
1. ç¬¬ä¸€ä¸ªçª—å£ï¼ˆå·¦ä¸Šè§’ 3x3 åŒºåŸŸï¼‰ï¼š(æœ€å¤§å€¼ä¸º9)
1  3  2
5  2  7
9  6  3

2. ç¬¬äºŒä¸ªçª—å£ï¼ˆå·¦ç§»ä¸€æ­¥ï¼Œä¿æŒé«˜åº¦ï¼Œå®½åº¦ +1ï¼‰ï¼š(æœ€å¤§å€¼ä¸º8)
3  2  4
2  7  1
6  3  8
```

æœ€ç»ˆå¾—åˆ°çš„ç‰¹å¾å›¾å¤§å°å¦‚ä¸‹ï¼š
```
9  8  8
9  8  8
9  7  9
```

å®æ“ä»£ç ç¤ºä¾‹å¦‚ä¸‹ï¼š

```python
from torch import reshape
from torch.utils.tensorboard import SummaryWriter
from torchvision import transforms, datasets
from torch.utils.data import DataLoader
import torch.nn as nn


class SimpleCNN(nn.Module):
    """ä¸€ä¸ªéå¸¸ç®€æ´çš„å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰ï¼Œç”¨äº CIFAR10 åˆ†ç±»ã€‚"""

    def __init__(self):
        super().__init__()
        self.max_pool = nn.MaxPool2d(
           kernel_size=3, stride=1, padding=1
        )

    def forward(self, x):
        x = self.max_pool(x)
        return x


def main():
    train_dataset = datasets.CIFAR10(
        root="./dataset", train=False, download=True, transform=transforms.ToTensor()
    )
    writer = SummaryWriter("logs")
    dataloader = DataLoader(train_dataset, batch_size=64)
    step = 0
    for batch in dataloader:
        images, labels = batch
        model = SimpleCNN()
        # å‰å‘ä¼ æ’­
        outputs = model(images)
        print(outputs.shape)
        writer.add_images("Maxpool Batch Origin", images, step)
        writer.add_images("Maxpool Batch Output", outputs, step)
        step += 1
    writer.close()


if __name__ == "__main__":
    main()

```

![alt text](æˆªå±2026-01-09%2000.16.25.png)

#### 2.3. éçº¿æ€§å±‚ï¼ˆæ¿€æ´»å‡½æ•°å±‚ï¼‰


éçº¿æ€§å±‚ï¼ˆä¹Ÿå«æ¿€æ´»å‡½æ•°å±‚ï¼‰æ˜¯ç¥ç»ç½‘ç»œä¸­å¼•å…¥éçº¿æ€§å˜æ¢çš„ç»„ä»¶ï¼Œå¸¸è§çš„æœ‰ `ReLU` ã€ `Sigmoid` ã€ `Tanh` ç­‰ã€‚éçº¿æ€§å±‚æ¯”è¾ƒç®€å•ï¼Œä¸»è¦ä½œç”¨æ˜¯å¼•å…¥éçº¿æ€§å˜æ¢ï¼Œä½¿ç¥ç»ç½‘ç»œèƒ½å¤Ÿå­¦ä¹ å¤æ‚çš„ç‰¹å¾è¡¨ç¤ºï¼Œè€Œä¸æ˜¯ç®€å•çš„çº¿æ€§å˜æ¢ã€‚

æˆ‘ä»¬å¯ä»¥é€šè¿‡æŸ¥çœ‹ PyTorch æ–‡æ¡£ä¸­çš„[éçº¿æ€§å±‚éƒ¨åˆ†](https://docs.pytorch.org/docs/stable/nn.html#non-linear-activations-weighted-sum-nonlinearity)æ¥äº†è§£æ›´å¤šä¿¡æ¯ã€‚



æ¯”å¦‚ `nn.ReLU` å±‚ï¼Œå®ƒçš„ä½œç”¨æ˜¯å¯¹è¾“å…¥è¿›è¡Œéçº¿æ€§å˜æ¢ï¼Œå°†æ‰€æœ‰è´Ÿå€¼è®¾ä¸º 0ï¼Œä¿æŒæ­£å€¼ä¸å˜ã€‚

$$
\text{ReLU}(x) = (x)^+ = \max(0, x)
$$

python ä»£ç ç¤ºä¾‹å¦‚ä¸‹ï¼š
```py
import torch
import torch.nn as nn


class SimpleCNN(nn.Module):
    """ä¸€ä¸ªéå¸¸ç®€æ´çš„å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰ï¼Œç”¨äº CIFAR10 åˆ†ç±»ã€‚"""

    def __init__(self):
        super().__init__()
        self.ReLU = nn.ReLU()

    def forward(self, x):
        x = self.ReLU(x)
        return x


def main():
    a = torch.randn(10)
    model = SimpleCNN()
    outputs = model(a)
    print(a,outputs)
    # tensor([ 0.3132, -0.0041, -0.9163,  1.1990, -0.4604, -1.4164, -0.2908, -1.6122,0.8373,  0.5947]) 
    # tensor([0.3132, 0.0000, 0.0000, 1.1990, 0.0000, 0.0000, 0.0000, 0.0000, 0.8373,0.5947])
```

#### 2.4. å…¨è¿æ¥å±‚ï¼ˆçº¿æ€§å±‚ï¼‰

å…¨è¿æ¥å±‚ï¼ˆä¹Ÿå«çº¿æ€§å±‚ï¼‰æ˜¯ç¥ç»ç½‘ç»œä¸­æœ€åŸºæœ¬çš„å±‚ï¼Œå®ƒçš„ä½œç”¨æ˜¯å¯¹è¾“å…¥è¿›è¡Œçº¿æ€§å˜æ¢ï¼Œè¾“å‡ºçš„ç»´åº¦å¯ä»¥ä»»æ„æŒ‡å®šã€‚

- 1. çº¿æ€§å±‚çš„æ•°å­¦åŸç†
çº¿æ€§å±‚çš„æ ¸å¿ƒæ˜¯æ‰§è¡Œä¸€ä¸ªçº¿æ€§å˜æ¢æ“ä½œï¼Œæ•°å­¦å…¬å¼è¡¨ç¤ºä¸ºï¼š

$$
Y = X \times W^T + b
$$

- 2. çº¿æ€§å±‚çš„ä½œç”¨
   - **ç‰¹å¾è½¬æ¢**ï¼šå°†è¾“å…¥ç‰¹å¾ä»ä¸€ä¸ªç»´åº¦ç©ºé—´è½¬æ¢åˆ°å¦ä¸€ä¸ªç»´åº¦ç©ºé—´
   - **ç‰¹å¾ç»„åˆ**ï¼šé€šè¿‡æƒé‡çŸ©é˜µå¯¹è¾“å…¥ç‰¹å¾è¿›è¡ŒåŠ æƒç»„åˆï¼Œå­¦ä¹ ç‰¹å¾ä¹‹é—´çš„å…³è”
   - **ä¿¡æ¯ä¼ é€’**ï¼šä½œä¸ºç¥ç»ç½‘ç»œå„å±‚ä¹‹é—´çš„ä¿¡æ¯ä¼ é€’æ¡¥æ¢

å…¨è¿æ¥å±‚é€šå¸¸ç”¨äºç¥ç»ç½‘ç»œçš„æœ€åå‡ å±‚ï¼Œç”¨äºå°†å‰é¢æå–çš„ç‰¹å¾è½¬æ¢ä¸ºæœ€ç»ˆçš„è¾“å‡ºï¼ˆå¦‚åˆ†ç±»ä»»åŠ¡çš„ç±»åˆ«æ¦‚ç‡ï¼‰ã€‚

- 3. ä»£ç ç¤ºä¾‹

```py
import torch
import torch.nn as nn

# åˆ›å»ºä¸€ä¸ªçº¿æ€§å±‚ï¼šè¾“å…¥ç»´åº¦10ï¼Œè¾“å‡ºç»´åº¦5
linear_layer = nn.Linear(in_features=10, out_features=5)

# éšæœºç”Ÿæˆè¾“å…¥å¼ é‡ (batch_size=2, input_features=10)
input_tensor = torch.randn(2, 10)

output_tensor = linear_layer(input_tensor)

print("è¾“å…¥å½¢çŠ¶:", input_tensor.shape)    # è¾“å‡º: torch.Size([2, 10])
print("è¾“å‡ºå½¢çŠ¶:", output_tensor.shape)   # è¾“å‡º: torch.Size([2, 5])
print("æƒé‡å½¢çŠ¶:", linear_layer.weight.shape)  # è¾“å‡º: torch.Size([5, 10])
print("åç½®å½¢çŠ¶:", linear_layer.bias.shape)    # è¾“å‡º: torch.Size([5])
```

#### 2.5. å°å®æˆ˜ï¼šå®ç°ä¸€ä¸ªCIFAR10åˆ†ç±»çš„ç¥ç»ç½‘ç»œæ¨¡å‹

æœ¬èŠ‚ï¼Œæˆ‘ä»¬å°†å®ç°ä¸€ä¸ªç®€å•çš„å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰ï¼Œç”¨äº CIFAR10 åˆ†ç±»ä»»åŠ¡ã€‚æˆ‘ä»¬å…ˆæœä¸€ä¸‹ CIFAR10 çš„å®ç°æ¨¡å‹ï¼š

![](./Structure-of-CIFAR10-quick-model.png)

æ ¹æ®ä¸Šå›¾æˆ‘ä»¬åˆ†æï¼ŒCIFAR10 åˆ†ç±»æ¨¡å‹çš„ç»“æ„å¦‚ä¸‹ï¼š

- è¾“å…¥ï¼š3@32x32ï¼ˆ3é€šé“RGBå›¾åƒï¼Œ32x32åƒç´ ï¼‰
- ç¬¬ä¸€å±‚å·ç§¯ï¼š5x5å·ç§¯æ ¸ï¼Œ32ä¸ªè¾“å‡ºé€šé“
- ç¬¬ä¸€å±‚æ± åŒ–ï¼š2x2æœ€å¤§æ± åŒ–
- ç¬¬äºŒå±‚å·ç§¯ï¼š5x5å·ç§¯æ ¸ï¼Œ32ä¸ªè¾“å‡ºé€šé“
- ç¬¬äºŒå±‚æ± åŒ–ï¼š2x2æœ€å¤§æ± åŒ–
- ç¬¬ä¸‰å±‚å·ç§¯ï¼š5x5å·ç§¯æ ¸ï¼Œ64ä¸ªè¾“å‡ºé€šé“
- ç¬¬ä¸‰å±‚æ± åŒ–ï¼š2x2æœ€å¤§æ± åŒ–
- æ‰å¹³å±‚ï¼šå°†64@4x4å±•å¹³ä¸º1024ä¸ªç‰¹å¾
- å…¨è¿æ¥å±‚ï¼š1024è¾“å…¥ï¼Œ10è¾“å‡ºï¼ˆå¯¹åº”CIFAR10çš„10ä¸ªç±»åˆ«ï¼‰

åˆ†æå¾—å‡ºæ¨¡å‹ç»“æ„åï¼Œæˆ‘ä»¬è¿˜éœ€è¦è€ƒè™‘å„ä¸ªå±‚çš„å‚æ•°é€‰æ‹©ï¼š

æ¯”å¦‚ç¬¬ä¸€å±‚å·ç§¯ä¸­ï¼Œå·ç§¯æ ¸å¤§å°ä¸º 5x5ï¼Œè¾“å…¥æ—¶å›¾ç‰‡å°ºå¯¸æ˜¯32ï¼Œè¾“å‡ºæ—¶å›¾ç‰‡å°ºå¯¸ä¹Ÿæ˜¯32ï¼Œé‚£ä¹ˆè‚¯å®šè®¾ç½®äº† `padding`ã€‚æ ¹æ®å·ç§¯å±‚çš„è¾“å‡ºå°ºå¯¸å…¬å¼ï¼š

$$H_{out} = \left\lfloor \frac{H_{in} - KernelSize + 2Padding}{Stride} + 1 \right\rfloor$$

æˆ‘ä»¬éœ€è¦åœ¨å·ç§¯å±‚ä¸­æ·»åŠ  `padding=2` æ¥ä¿æŒè¾“å‡ºå°ºå¯¸ä¸º 32x32ã€‚

ç°åœ¨ï¼Œæˆ‘ä»¬å°±å¯ä»¥æ¥å®ç°è¿™ä¸ªæ¨¡å‹äº†ï¼š

```py
class CIFAR10CNN(nn.Module):    
    """ä¸€ä¸ªç”¨äºCIFAR10åˆ†ç±»çš„å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰ï¼Œç»“æ„å¦‚ä¸‹ï¼š
    - è¾“å…¥ï¼š3@32x32ï¼ˆ3é€šé“RGBå›¾åƒï¼Œ32x32åƒç´ ï¼‰
    - ç¬¬ä¸€å±‚å·ç§¯ï¼š5x5å·ç§¯æ ¸ï¼Œ32ä¸ªè¾“å‡ºé€šé“ï¼Œpadding=2ä¿æŒå°ºå¯¸
    - ç¬¬ä¸€å±‚æ± åŒ–ï¼š2x2æœ€å¤§æ± åŒ–ï¼Œæ­¥é•¿2ï¼Œå°ºå¯¸å‡åŠ
    - ç¬¬äºŒå±‚å·ç§¯ï¼š5x5å·ç§¯æ ¸ï¼Œ32ä¸ªè¾“å‡ºé€šé“ï¼Œpadding=2ä¿æŒå°ºå¯¸
    - ç¬¬äºŒå±‚æ± åŒ–ï¼š2x2æœ€å¤§æ± åŒ–ï¼Œæ­¥é•¿2ï¼Œå°ºå¯¸å‡åŠ
    - ç¬¬ä¸‰å±‚å·ç§¯ï¼š5x5å·ç§¯æ ¸ï¼Œ64ä¸ªè¾“å‡ºé€šé“ï¼Œpadding=2ä¿æŒå°ºå¯¸
    - ç¬¬ä¸‰å±‚æ± åŒ–ï¼š2x2æœ€å¤§æ± åŒ–ï¼Œæ­¥é•¿2ï¼Œå°ºå¯¸å‡åŠ
    - æ‰å¹³å±‚ï¼šå°†64@4x4å±•å¹³ä¸º1024ä¸ªç‰¹å¾
    - å…¨è¿æ¥å±‚ï¼š1024è¾“å…¥ï¼Œ10è¾“å‡ºï¼ˆå¯¹åº”CIFAR10çš„10ä¸ªç±»åˆ«ï¼‰
    """

    def __init__(self):
        super().__init__()
        # (32 - 5 + 2*padding)/1 + 1 = 32 => padding = 2
        self.conv1 = nn.Conv2d(in_channels=3,out_channels=32,kernel_size=5,padding=2)
        # (32 - 2)/s+1 = 16 => s = 2
        self.p1 = nn.MaxPool2d(kernel_size=2, stride=2)

        # (16 - 5 + 2*p) +1 = 16 => padding = 2
        self.conv2 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=5, padding=2)

        # (16 - 2)/s +1 = 8 => s = 2
        self.p2 = nn.MaxPool2d(kernel_size=2, stride=2)

        # (8 - 5 + 2*p) +1 = 8 => padding = 2
        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5, padding=2)

        # (8 - 2)/s +1 = 4 => s = 2
        self.p3 = nn.MaxPool2d(kernel_size=2, stride=2)

        # å…¨è¿æ¥å±‚
        self.linear = nn.Linear(64 * 4 * 4, 10)

    def forward(self, x):
        # è¾“å…¥å½¢çŠ¶: [batch_size, 3, 32, 32]
        
        # ç¬¬ä¸€å±‚å·ç§¯ + æ¿€æ´» + æ± åŒ–
        x = self.conv1(x)  # è¾“å‡ºå½¢çŠ¶: [batch_size, 32, 32, 32]
        x = self.p1(x)               # è¾“å‡ºå½¢çŠ¶: [batch_size, 32, 16, 16]
        
        # ç¬¬äºŒå±‚å·ç§¯ + æ¿€æ´» + æ± åŒ–
        x = self.conv2(x)  # è¾“å‡ºå½¢çŠ¶: [batch_size, 32, 16, 16]
        x = self.p2(x)               # è¾“å‡ºå½¢çŠ¶: [batch_size, 32, 8, 8]
        
        # ç¬¬ä¸‰å±‚å·ç§¯ + æ¿€æ´» + æ± åŒ–
        x = self.conv3(x)  # è¾“å‡ºå½¢çŠ¶: [batch_size, 64, 8, 8]
        x = self.p3(x)               # è¾“å‡ºå½¢çŠ¶: [batch_size, 64, 4, 4]
        
        # æ‰å¹³å±‚
        x = torch.flatten(x, 1)        # è¾“å‡ºå½¢çŠ¶: [batch_size, 64*4*4=1024]
        
        # å…¨è¿æ¥å±‚
        x = self.linear(x)                 # è¾“å‡ºå½¢çŠ¶: [batch_size, 10]
        
        return x
```


#### 2.6. æŸå¤±å‡½æ•°ï¼ˆLoss Functionï¼‰å’Œåå‘ä¼ æ’­ï¼ˆBackpropagationï¼‰

æŸå¤±å‡½æ•°ï¼ˆLoss Functionï¼‰æ˜¯ç¥ç»ç½‘ç»œä¸­ç”¨äºè¡¡é‡æ¨¡å‹é¢„æµ‹å€¼ä¸çœŸå®å€¼ä¹‹é—´å·®å¼‚çš„å‡½æ•°ã€‚å®ƒçš„ä½œç”¨æ˜¯åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œé€šè¿‡æœ€å°åŒ–æŸå¤±å‡½æ•°çš„å€¼ï¼Œæ¥ä¼˜åŒ–æ¨¡å‹çš„å‚æ•°ï¼Œä»è€Œå®ç°å¯¹æ•°æ®çš„å‡†ç¡®é¢„æµ‹ã€‚ä¸‹é¢æˆ‘ä»¬æ¥ä»‹ç»ä¸€ä¸‹å¸¸ç”¨çš„æŸå¤±å‡½æ•°ã€‚

##### 2.6.1. L1Loss

æ‹¿æœ€ç®€å•çš„ L1Loss æŸå¤±å‡½æ•°ä¸ºä¾‹ï¼š

$$
L1Loss = \frac{1}{n} \sum_{i=1}^n |y_i - \hat{y}_i|
$$

å…¶ä¸­ï¼Œ$y_i$ æ˜¯çœŸå®å€¼ï¼Œ$\hat{y}_i$ æ˜¯æ¨¡å‹é¢„æµ‹å€¼ï¼Œ$n$ æ˜¯æ ·æœ¬æ•°é‡ã€‚L1Loss çš„ä½œç”¨æ˜¯è®¡ç®—æ¨¡å‹é¢„æµ‹å€¼ä¸çœŸå®å€¼ä¹‹é—´çš„å¹³å‡ç»å¯¹è¯¯å·®ã€‚

```py
def loss_fn():
    loss_mean = nn.L1Loss(reduction="mean")
    loss_sum = nn.L1Loss(reduction="sum")
    input = torch.tensor([1, 2, 3, 4, 5])
    target = torch.tensor([1.5, 2.5, 3.5, 4.5, 5.5])
    output_mean = loss_mean(input, target)
    output_sum = loss_sum(input, target)
    print(output_mean)
    print(output_sum)

    # tensor(0.5000)
    # tensor(2.5000)
```

##### 2.6.2. MSELoss

æ¯”è¾ƒå¸¸ç”¨çš„è¿˜æœ‰ `nn.MSELoss` æŸå¤±å‡½æ•°ï¼Œå®ƒçš„ä½œç”¨æ˜¯è®¡ç®—æ¨¡å‹é¢„æµ‹å€¼ä¸çœŸå®å€¼ä¹‹é—´çš„å‡æ–¹è¯¯å·®ã€‚

$$
MSELoss = \frac{1}{n} \sum_{i=1}^n (y_i - \hat{y}_i)^2
$$

å…¶ä¸­ï¼Œ$y_i$ æ˜¯çœŸå®å€¼ï¼Œ$\hat{y}_i$ æ˜¯æ¨¡å‹é¢„æµ‹å€¼ï¼Œ$n$ æ˜¯æ ·æœ¬æ•°é‡ã€‚MSELoss çš„ä½œç”¨æ˜¯è®¡ç®—æ¨¡å‹é¢„æµ‹å€¼ä¸çœŸå®å€¼ä¹‹é—´çš„å‡æ–¹è¯¯å·®ã€‚

```py
def loss_fn2():
    loss_mean = nn.MSELoss(reduction="mean")
    loss_sum = nn.MSELoss(reduction="sum")
    input = torch.tensor([1, 2, 3, 4, 5])
    target = torch.tensor([1.5, 2.5, 3.5, 4.5, 5.5])
    output_mean = loss_mean(input, target)
    output_sum = loss_sum(input, target)
    print(output_mean)
    print(output_sum)
    # tensor(0.2500): (0.5^2 + 0.5^2 + 0.5^2 + 0.5^2 + 0.5^2) / 5 = 0.25
    # tensor(1.2500)
```

##### 2.6.3. CrossEntropyLoss å’Œ NLLLoss äº¤å‰ç†µæŸå¤±å‡½æ•°

äº¤å‰ç†µæŸå¤±å‡½æ•°ï¼ˆCrossEntropyLossï¼‰æ˜¯ä¸“é—¨ç”¨äºC åˆ†ç±»é—®é¢˜ï¼ˆå³æ•°æ®æœ‰ C ä¸ªç±»åˆ«ï¼Œå¦‚ 10 åˆ†ç±»çš„å›¾åƒè¯†åˆ«ï¼‰ï¼Œå®ƒçš„ä½œç”¨æ˜¯è®¡ç®—æ¨¡å‹é¢„æµ‹å€¼ä¸çœŸå®å€¼ä¹‹é—´çš„äº¤å‰ç†µã€‚å®ƒæ”¯æŒé€šè¿‡weightå‚æ•°ï¼ˆ1 ç»´ Tensorï¼Œé•¿åº¦ä¸º Cï¼‰ä¸ºæ¯ä¸ªç±»åˆ«åˆ†é…æƒé‡ï¼Œå¯è§£å†³è®­ç»ƒé›†ç±»åˆ«ä¸å¹³è¡¡é—®é¢˜ï¼ˆä¾‹å¦‚æŸç±»æ ·æœ¬æå°‘ï¼Œéœ€æé«˜å…¶æƒé‡ä»¥é¿å…æ¨¡å‹å¿½ç•¥è¯¥ç±»ï¼‰ã€‚

å…¶æ•°å­¦è®¡ç®—å…¬å¼å¦‚ä¸‹ï¼š

$$
\text{loss}(x, class) = -\log\left(\frac{\exp(x[class])}{\sum_j \exp(x[j])}\right) = -x[class] + \log\left(\sum_j \exp(x[j])\right)
$$


NLLLoss æ˜¯ CrossEntropyLoss çš„ä¸€ä¸ªç‰¹æ®Šæƒ…å†µï¼Œå½“æ¨¡å‹è¾“å‡ºçš„æ˜¯å¯¹æ•°æ¦‚ç‡ï¼ˆlog probabilitiesï¼‰æ—¶ï¼Œå¯ä»¥ç›´æ¥ä½¿ç”¨ NLLLoss ã€‚

å…¶æ•°å­¦è®¡ç®—å…¬å¼å¦‚ä¸‹ï¼š

$$
Loss = \frac{1}{N} \sum_{n=1}^N -x_{n, y_n}
$$

ä¸¾ä¸ªä¾‹å­ï¼Œæˆ‘æƒ³é€šè¿‡å°†ä¸€äº›åŠ¨ç‰©å›¾ç‰‡è¿›è¡Œåˆ†ç±»ï¼Œå¯é€‰ç±»åˆ«å…±æœ‰ä¸‰ç§ï¼šçŒ«ã€ç‹—ã€çŒªã€‚å‡è®¾æˆ‘ä»¬æ‰‹å¤´æœ‰ä¸¤ä¸ªå‚æ•°ä¸åŒçš„æ¨¡å‹ï¼Œå®ƒä»¬éƒ½é€šè¿‡ sigmoid/softmax è¾“å‡ºæ¯ä¸ªç±»åˆ«çš„æ¦‚ç‡åˆ†å¸ƒï¼š

> å‚è€ƒæ–‡æ¡£ï¼šhttps://www.zhihu.com/tardis/zm/art/35709485?source_id=1003

**æ¨¡å‹1ï¼š**

| é¢„æµ‹ | çœŸå® | æ˜¯å¦æ­£ç¡® |
| :--- | :--- | :--- |
| 0.3 0.3 0.4 | 0 0 1 (çŒª) | æ­£ç¡® |
| 0.3 0.4 0.3 | 0 1 0 (ç‹—) | æ­£ç¡® |
| 0.1 0.2 0.7 | 1 0 0 (çŒ«) | é”™è¯¯ |

æ¨¡å‹1å¯¹äºæ ·æœ¬1å’Œæ ·æœ¬2ä»¥éå¸¸å¾®å¼±çš„ä¼˜åŠ¿åˆ¤æ–­æ­£ç¡®ï¼Œå¯¹äºæ ·æœ¬3çš„åˆ¤æ–­åˆ™å½»åº•é”™è¯¯ã€‚

---

**æ¨¡å‹2ï¼š**

| é¢„æµ‹ | çœŸå® | æ˜¯å¦æ­£ç¡® |
| :--- | :--- | :--- |
| 0.1 0.2 0.7 | 0 0 1 (çŒª) | æ­£ç¡® |
| 0.1 0.7 0.2 | 0 1 0 (ç‹—) | æ­£ç¡® |
| 0.3 0.4 0.3 | 1 0 0 (çŒ«) | é”™è¯¯ |

æ¨¡å‹2å¯¹äºæ ·æœ¬1å’Œæ ·æœ¬2åˆ¤æ–­éå¸¸å‡†ç¡®ï¼Œå¯¹äºæ ·æœ¬3åˆ¤æ–­é”™è¯¯ï¼Œä½†æ˜¯ç›¸å¯¹æ¥è¯´æ²¡æœ‰é”™å¾—å¤ªç¦»è°±ã€‚

æˆ‘ä»¬å¯ä»¥é€šè¿‡è®¡ç®—æ¨¡å‹1å’Œæ¨¡å‹2çš„äº¤å‰ç†µæŸå¤±æ¥æ¯”è¾ƒå®ƒä»¬çš„æ€§èƒ½ï¼š

**æ¨¡å‹1çš„äº¤å‰ç†µæŸå¤±ï¼š**

åœ¨è¿™é‡Œï¼Œ$p_{target}^{(i)}$ ä»£è¡¨æ¨¡å‹å¯¹ç¬¬ $i$ ä¸ªæ ·æœ¬**çœŸå®ç±»åˆ«**çš„é¢„æµ‹æ¦‚ç‡ã€‚

- **æ ·æœ¬1**ï¼šçœŸå®ç±»åˆ«æ˜¯â€œçŒªâ€ï¼Œæ¨¡å‹1é¢„æµ‹â€œçŒªâ€çš„æ¦‚ç‡æ˜¯ **0.4**ã€‚
- **æ ·æœ¬2**ï¼šçœŸå®ç±»åˆ«æ˜¯â€œç‹—â€ï¼Œæ¨¡å‹1é¢„æµ‹â€œç‹—â€çš„æ¦‚ç‡æ˜¯ **0.4**ã€‚
- **æ ·æœ¬3**ï¼šçœŸå®ç±»åˆ«æ˜¯â€œçŒ«â€ï¼Œæ¨¡å‹1é¢„æµ‹â€œçŒ«â€çš„æ¦‚ç‡æ˜¯ **0.1**ã€‚

æ‰€ä»¥è®¡ç®—è¿‡ç¨‹å¦‚ä¸‹ï¼š

$$
\begin{aligned}
Loss_1 &= \frac{1}{3} \sum_{i=1}^3 -\log(p_{target}^{(i)}) \\
&= \frac{1}{3} ( \underbrace{-\log(0.4)}_{\text{sample1(pig)}} + \underbrace{-\log(0.4)}_{\text{sample2(dog)}} + \underbrace{-\log(0.1)}_{\text{sample3(cat)}} ) \\
&\approx \frac{1}{3} (0.916 + 0.916 + 2.302) \\
&= 1.378
\end{aligned}
$$

**æ¨¡å‹2çš„äº¤å‰ç†µæŸå¤±ï¼š**

åŒç†ï¼Œå¯¹äºæ¨¡å‹2ï¼š
- **æ ·æœ¬1**ï¼ˆçŒªï¼‰ï¼šé¢„æµ‹æ¦‚ç‡ **0.7**ã€‚
- **æ ·æœ¬2**ï¼ˆç‹—ï¼‰ï¼šé¢„æµ‹æ¦‚ç‡ **0.7**ã€‚
- **æ ·æœ¬3**ï¼ˆçŒ«ï¼‰ï¼šé¢„æµ‹æ¦‚ç‡ **0.3**ã€‚

$$
\begin{aligned}
Loss_2 &= \frac{1}{3} \sum_{i=1}^3 -\log(p_{target}^{(i)}) \\
&= \frac{1}{3} ( \underbrace{-\log(0.7)}_{\text{sample1}} + \underbrace{-\log(0.7)}_{\text{sample2}} + \underbrace{-\log(0.3)}_{\text{sample3}} ) \\
&\approx \frac{1}{3} (0.357 + 0.357 + 1.204) \\
&= 0.639
\end{aligned}
$$

ä»ç»“æœå¯ä»¥çœ‹å‡ºï¼Œ$Loss_2 < Loss_1$ï¼Œè¯´æ˜æ¨¡å‹2çš„é¢„æµ‹ç»“æœä¸çœŸå®å€¼æ›´æ¥è¿‘ï¼Œæ€§èƒ½ä¼˜äºæ¨¡å‹1ã€‚

##### 2.6.4. CrossEntropyLoss è®¡ç®—å®æˆ˜ï¼ˆä»£ç è¯¦è§£ï¼‰

è¿™é‡Œåœ¨å†™ä»£ç å‰è¦æ³¨æ„ä¸€ä¸‹ï¼Œç”±äº nn.CrossEntropyLoss æ¥æ”¶çš„æ˜¯â€œæœªå½’ä¸€åŒ–çš„å¯¹æ•°æ¦‚ç‡â€ï¼ˆlogitsï¼‰ï¼Œ
è€Œæˆ‘ä»¬è¿™é‡Œå·²çŸ¥çš„æ˜¯ç»è¿‡ Softmax åçš„â€œæ¦‚ç‡â€ã€‚æ‰€ä»¥æˆ‘ä»¬éœ€è¦å…ˆæ‰‹åŠ¨å–å¯¹æ•° (torch.log)ï¼Œ
ç„¶åä½¿ç”¨ NLLLoss (Negative Log Likelihood Loss)ã€‚

å…¬å¼å…³ç³»ï¼š`CrossEntropyLoss(logits) = NLLLoss(log_softmax(logits))`

```py
import torch
import torch.nn as nn
import math


def calculate_pytorch_loss(probs_tensor, targets_tensor, model_name):
    criterion = nn.NLLLoss(reduction="mean")
    log_probs = torch.log(probs_tensor)
    loss = criterion(log_probs, targets_tensor)
    return loss.item()


def main():
    # æ•°æ®å‡†å¤‡
    # ç±»åˆ«æ˜ å°„: 0:çŒ«, 1:ç‹—, 2:çŒª

    # --- æ¨¡å‹ 1 æ•°æ® ---
    # æ ·æœ¬1: é¢„æµ‹[0.3, 0.3, 0.4], çœŸå®: çŒª(2)
    # æ ·æœ¬2: é¢„æµ‹[0.3, 0.4, 0.3], çœŸå®: ç‹—(1)
    # æ ·æœ¬3: é¢„æµ‹[0.1, 0.2, 0.7], çœŸå®: çŒ«(0)
    model1_probs = torch.tensor(
        [[0.3, 0.3, 0.4], [0.3, 0.4, 0.3], [0.1, 0.2, 0.7]], dtype=torch.float32
    )
    model1_targets = torch.tensor([2, 1, 0], dtype=torch.long)

    # --- æ¨¡å‹ 2 æ•°æ® ---
    # æ ·æœ¬1: é¢„æµ‹[0.1, 0.2, 0.7], çœŸå®: çŒª(2)
    # æ ·æœ¬2: é¢„æµ‹[0.1, 0.7, 0.2], çœŸå®: ç‹—(1)
    # æ ·æœ¬3: é¢„æµ‹[0.3, 0.4, 0.3], çœŸå®: çŒ«(0)
    model2_probs = torch.tensor(
        [[0.1, 0.2, 0.7], [0.1, 0.7, 0.2], [0.3, 0.4, 0.3]], dtype=torch.float32
    )
    model2_targets = torch.tensor([2, 1, 0], dtype=torch.long)
    # --- æ‰§è¡Œè®¡ç®— ---
    calculate_pytorch_loss(model1_probs, model1_targets, "æ¨¡å‹ 1")
    calculate_pytorch_loss(model2_probs, model2_targets, "æ¨¡å‹ 2")


if __name__ == "__main__":
    main()

```

##### 2.6.5. åå‘ä¼ æ’­ï¼ˆBackpropagationï¼‰

åå‘ä¼ æ’­ï¼ˆBackpropagationï¼‰æ˜¯ç¥ç»ç½‘ç»œè®­ç»ƒä¸­é‡è¦çš„ä¸€æ­¥ï¼Œåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬æœ€ç»ˆå¸Œæœ›èƒ½æŠŠæŸå¤±å‡½æ•°çš„å€¼æœ€å°åŒ–ï¼Œä»è€Œä½¿æ¨¡å‹çš„é¢„æµ‹ç»“æœä¸çœŸå®å€¼æ›´æ¥è¿‘ã€‚ä¸ºäº†å®ç°è¿™ä¸€ç›®æ ‡ï¼Œæˆ‘ä»¬éœ€è¦è®¡ç®—æŸå¤±å‡½æ•°å…³äºæ¨¡å‹å‚æ•°çš„æ¢¯åº¦ï¼Œç„¶åæ ¹æ®æ¢¯åº¦æ›´æ–°å‚æ•°ã€‚

åå‘ä¼ æ’­çš„è¿‡ç¨‹å¯ä»¥ç®€å•æè¿°ä¸ºï¼š
1. å‰å‘ä¼ æ’­ï¼šä»è¾“å…¥å±‚å¼€å§‹ï¼Œä¾æ¬¡è®¡ç®—æ¯ä¸ªç¥ç»å…ƒçš„è¾“å‡ºï¼Œç›´åˆ°è¾“å‡ºå±‚ã€‚
2. è®¡ç®—æŸå¤±ï¼šå°†è¾“å‡ºå±‚çš„è¾“å‡ºä¸çœŸå®å€¼è¿›è¡Œæ¯”è¾ƒï¼Œè®¡ç®—æŸå¤±å‡½æ•°çš„å€¼ã€‚
3. åå‘ä¼ æ’­ï¼šä»è¾“å‡ºå±‚å¼€å§‹ï¼Œä¾æ¬¡è®¡ç®—æ¯ä¸ªç¥ç»å…ƒçš„æ¢¯åº¦ï¼Œç›´åˆ°è¾“å…¥å±‚ã€‚
4. æ›´æ–°å‚æ•°ï¼šæ ¹æ®è®¡ç®—å¾—åˆ°çš„æ¢¯åº¦ï¼Œä½¿ç”¨ä¼˜åŒ–ç®—æ³•ï¼ˆå¦‚æ¢¯åº¦ä¸‹é™ï¼‰æ›´æ–°æ¨¡å‹å‚æ•°ã€‚

é€šè¿‡é‡å¤æ‰§è¡Œå‰å‘ä¼ æ’­ã€è®¡ç®—æŸå¤±ã€åå‘ä¼ æ’­å’Œå‚æ•°æ›´æ–°æ­¥éª¤ï¼Œæˆ‘ä»¬å¯ä»¥é€æ¸ä¼˜åŒ–æ¨¡å‹çš„å‚æ•°ï¼Œä½¿æŸå¤±å‡½æ•°çš„å€¼ä¸æ–­å‡å°ï¼Œä»è€Œæé«˜æ¨¡å‹çš„æ€§èƒ½ã€‚

ä»¥ä¹‹å‰æˆ‘ä»¬è‡ªå·±å®ç°çš„ CIFAR10 åˆ†ç±»æ¨¡å‹ä¸ºä¾‹ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡åå‘ä¼ æ’­æ¥æ›´æ–°æ¨¡å‹å‚æ•°ã€‚

```python
def main():
    dataset = datasets.CIFAR10(
        root="./dataset", train=False, download=True, transform=transforms.ToTensor()
    )
    dataloader = DataLoader(dataset, batch_size=1, shuffle=False)
    loss = nn.CrossEntropyLoss()

    for batch in dataloader:
        images, labels = batch
        model = CIFAR10CNN()
        # å‰å‘ä¼ æ’­
        outputs = model(images)
        # è®¡ç®—æŸå¤±
        loss_value = loss(outputs, labels)
        # åå‘ä¼ æ’­
        # è®¡ç®—å‡ºçš„ loss å€¼å…·å¤‡ backward æ–¹æ³•ï¼Œè°ƒç”¨åå¯è‡ªåŠ¨å®Œæˆåå‘ä¼ æ’­ï¼Œä¸ºæ¯ä¸ªå¯è®­ç»ƒå‚æ•°è®¡ç®—æ¢¯åº¦ã€‚  
        # åˆå§‹æ—¶ç½‘ç»œå‚æ•°çš„ grad å±æ€§ä¸ºç©ºï¼Œæ‰§è¡Œ backward åæ¢¯åº¦è¢«å†™å…¥ï¼Œä¾›ä¼˜åŒ–å™¨æ›´æ–°ç½‘ç»œå‚æ•°ã€‚
        loss_value.backward()
```


#### 2.7. ä¼˜åŒ–å™¨

ä¼˜åŒ–å™¨ï¼ˆOptimizerï¼‰æ˜¯ç¥ç»ç½‘ç»œè®­ç»ƒä¸­ç”¨äºæ›´æ–°æ¨¡å‹å‚æ•°çš„ç®—æ³•ã€‚å®ƒçš„ä½œç”¨æ˜¯æ ¹æ®æŸå¤±å‡½æ•°å…³äºå‚æ•°çš„æ¢¯åº¦ï¼Œ
é€šè¿‡è¿­ä»£åœ°è°ƒæ•´å„ç½‘ç»œå±‚çš„å‚æ•°ï¼Œä½¿æŸå¤±å‡½æ•°çš„å€¼ä¸æ–­å‡å°ï¼Œä»è€Œæé«˜æ¨¡å‹çš„æ€§èƒ½ã€‚

å¸¸ç”¨çš„ä¼˜åŒ–å™¨åŒ…æ‹¬ï¼š
- æ¢¯åº¦ä¸‹é™ï¼ˆGradient Descentï¼‰
- åŠ¨é‡æ¢¯åº¦ä¸‹é™ï¼ˆMomentum Gradient Descentï¼‰
- è‡ªé€‚åº”å­¦ä¹ ç‡æ–¹æ³•ï¼ˆAdaptive Learning Rate Methodsï¼‰
  - Adam
  - RMSProp
- å…¶ä»–ä¼˜åŒ–å™¨ï¼ˆå¦‚ SGD with Nesterov Momentumï¼‰

**è¦æ³¨æ„çš„æ˜¯ï¼Œè®­ç»ƒæ¨¡å‹æ—¶ï¼Œæˆ‘ä»¬åªéœ€è¦åšåˆ° 3 ä¸ªæ­¥éª¤ï¼š**

- æ¸…ç©ºæ¢¯åº¦ - `optimizer.zero_grad()`
- åå‘ä¼ æ’­ - `loss_value.backward()`
- å¼€å§‹è®­ç»ƒï¼ˆæ›´æ–°æ¨¡å‹å‚æ•°ï¼‰ - `optimizer.step()`


```py
def main():
    dataset = datasets.CIFAR10(
        root="./dataset", train=False, download=True, transform=transforms.ToTensor()
    )
    dataloader = DataLoader(dataset, batch_size=1, shuffle=False)
    loss = nn.CrossEntropyLoss()
    # åˆå§‹åŒ–ä¼˜åŒ–å™¨
    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)
    for batch in dataloader:
        images, labels = batch
        model = CIFAR10CNN()
        # å‰å‘ä¼ æ’­
        outputs = model(images)
        # è®¡ç®—æŸå¤±
        loss_value = loss(outputs, labels)
        # ä¼˜åŒ–å™¨æ›´æ–°å‚æ•°å‰ï¼Œéœ€è¦å…ˆå°†æ¢¯åº¦æ¸…é›¶, å¦åˆ™æ¢¯åº¦ä¼šç´¯åŠ , å¯¼è‡´é”™è¯¯çš„å‚æ•°æ›´æ–°
        optimizer.zero_grad()
        loss_value.backward()
        # ä¼˜åŒ–å™¨æ ¹æ®è®¡ç®—å¾—åˆ°çš„æ¢¯åº¦ï¼Œæ›´æ–°æ¨¡å‹å‚æ•°
        optimizer.step()
```

#### 2.8. ç¥ç»ç½‘ç»œçš„ä¸‹è½½å’Œä¿®æ”¹

é™¤äº†æˆ‘ä»¬è‡ªå·±æ­å»ºç¥ç»ç½‘ç»œå¤–ï¼Œæˆ‘ä»¬æ›´å¤šåœ°æ˜¯å»ä¸‹è½½ç°æˆçš„ç¥ç»ç½‘ç»œæ¥ç›´æ¥ä½¿ç”¨ã€‚ [torchvision.models](https://pytorch.org/vision/stable/models.html)

`torchvision.models` å­åŒ…åŒ…å«ç”¨äºè§£å†³ä¸åŒä»»åŠ¡çš„æ¨¡å‹å®šä¹‰ï¼ŒåŒ…æ‹¬ï¼šå›¾åƒåˆ†ç±»ã€é€åƒç´ è¯­ä¹‰åˆ†å‰²ã€ç›®æ ‡æ£€æµ‹ã€å®ä¾‹åˆ†å‰²ã€äººä½“å…³é”®ç‚¹æ£€æµ‹ã€è§†é¢‘åˆ†ç±»å’Œå…‰æµã€‚

æ¯”å¦‚æˆ‘ä»¬è¦ä¸‹è½½ä¸€ä¸ªç”¨äºå›¾åƒåˆ†ç±»çš„æ¨¡å‹ `ResNet50`ï¼Œæˆ‘ä»¬å¯ä»¥è¿™æ ·åšï¼š

```py
import torchvision.models as models, ResNet50_Weights

# ä¸‹è½½é¢„è®­ç»ƒçš„ ResNet - 50 æ¨¡å‹
# Old weights with accuracy 76.130%
resnet50(weights=ResNet50_Weights.IMAGENET1K_V1)

# New weights with accuracy 80.858%
resnet50(weights=ResNet50_Weights.IMAGENET1K_V2)

# no weights
resnet50()
```

ä½¿ç”¨æ–¹å¼ä¹Ÿå¾ˆç®€å•ï¼š

```py
import torch
import torchvision.models as models
from torchvision.models import ResNet50_Weights

# ä¸‹è½½é¢„è®­ç»ƒçš„ ResNet - 50 æ¨¡å‹
model = models.resnet50(weights=ResNet50_Weights.IMAGENET1K_V1)

print(model)


"""
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer2): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (3): Bottleneck(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer3): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (3): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (4): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (5): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer4): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (fc): Linear(in_features=2048, out_features=1000, bias=True)
)
"""

```

ResNet50 æ˜¯è®¡ç®—æœºè§†è§‰é¢†åŸŸéå¸¸è‘—åçš„æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œå®ƒæ›¾è·å¾— ImageNet å›¾åƒåˆ†ç±»ç«èµ›çš„å† å†›ã€‚è¿™é‡Œçš„ "50" æŒ‡çš„æ˜¯è¿™ä¸ªç½‘ç»œä¸€å…±æœ‰ 50 å±‚ï¼ˆåŒ…å«å·ç§¯å±‚å’Œå…¨è¿æ¥å±‚ï¼‰ã€‚

è¿™é‡Œä¸»è¦åˆ†ä¸º 4 ä¸ªé˜¶æ®µï¼š

- **1. é¢„å¤„ç†é˜¶æ®µï¼ˆå›¾åƒåˆšè¿›å…¥ç½‘ç»œï¼‰**

```py
(conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
(bn1): BatchNorm2d(64, ...)
(relu): ReLU(inplace=True)
(maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, ...)
```
- Conv2d (å·ç§¯å±‚) ï¼šè¿™æ˜¯æµæ°´çº¿çš„ç¬¬ä¸€é“å·¥åºã€‚
  - `(3, 64)` ï¼šè¾“å…¥æ˜¯ 3 ä¸ªé€šé“ï¼ˆå› ä¸ºå›¾ç‰‡æ˜¯ RGB å½©è‰²çš„ï¼‰ï¼Œè¾“å‡ºå˜æˆäº† 64 ä¸ªç‰¹å¾é€šé“ã€‚ä½ å¯ä»¥ç†è§£ä¸ºå®ƒæå–äº† 64 ç§ä¸åŒçš„åŸºç¡€ç‰¹å¾ï¼ˆæ¯”å¦‚è¾¹ç¼˜ã€é¢œè‰²æ–‘ç‚¹ç­‰ï¼‰ã€‚
  - `kernel_size=(7, 7)` ï¼šè¿™æ˜¯ä¸€ä¸ªå¾ˆå¤§çš„â€œæ‰«æçª—å£â€ï¼Œä¸€æ¬¡çœ‹ 7x7 åƒç´ çš„åŒºåŸŸã€‚
  - `stride=(2, 2)` ï¼šæ­¥é•¿æ˜¯ 2ï¼Œè¯´æ˜çª—å£æ¯æ¬¡ç§»åŠ¨ 2 æ ¼ã€‚è¿™ä¼šè®©å›¾ç‰‡çš„ é•¿å®½ç¼©å°ä¸€åŠ ï¼ˆä¾‹å¦‚ä» 224x224 å˜æˆ 112x112ï¼‰ã€‚
- BatchNorm2d (BNå±‚) ï¼šè¿™ç›¸å½“äºâ€œè´¨æ£€å’Œæ ‡å‡†åŒ–â€ã€‚å®ƒæŠŠæ•°æ®è°ƒæ•´åˆ°ä¸€ä¸ªæ ‡å‡†çš„åˆ†å¸ƒï¼Œé˜²æ­¢æ•°æ®åœ¨ä¼ è¾“è¿‡ç¨‹ä¸­å˜å¾—è¿‡å¤§æˆ–è¿‡å°ï¼Œè®©ç½‘ç»œæ›´å®¹æ˜“è®­ç»ƒã€‚
- ReLU (æ¿€æ´»å‡½æ•°) ï¼šè¿™ç›¸å½“äºä¸€ä¸ªâ€œå¼€å…³â€ã€‚å®ƒæŠŠæ‰€æœ‰è´Ÿæ•°å€¼å˜æˆ 0ï¼Œæ­£æ•°å€¼ä¿æŒä¸å˜ã€‚è¿™ç»™ç½‘ç»œå¼•å…¥äº†éçº¿æ€§ï¼Œè®©å®ƒèƒ½å¤„ç†å¤æ‚ä»»åŠ¡ã€‚
- MaxPool2d (æœ€å¤§æ± åŒ–å±‚) ï¼šè¿™ç›¸å½“äºâ€œç²¾ç®€æ•°æ®â€ã€‚å®ƒåœ¨ 3x3 çš„åŒºåŸŸé‡Œåªå–æœ€å¤§çš„é‚£ä¸ªå€¼ã€‚ stride=2 å†æ¬¡è®©å›¾ç‰‡çš„ é•¿å®½ç¼©å°ä¸€åŠ ï¼ˆä¾‹å¦‚ä» 112x112 å˜æˆ 56x56ï¼‰ã€‚

æ€»ç»“ ï¼šè¿™ä¸€é˜¶æ®µä¸»è¦æ˜¯å¿«é€Ÿé™ä½å›¾ç‰‡å°ºå¯¸ï¼Œæå–åˆæ­¥ç‰¹å¾ã€‚

- **2. æ ¸å¿ƒåŠ å·¥é˜¶æ®µ ï¼ˆ4 ä¸ª Layerï¼‰**

æ¥ä¸‹æ¥æ˜¯ ResNet çš„æ ¸å¿ƒéƒ¨åˆ†ï¼Œç”± layer1 åˆ° layer4 ç»„æˆã€‚å®ƒä»¬æ˜¯ç”±ä¸€ç§å« Bottleneckï¼ˆç“¶é¢ˆç»“æ„ï¼‰ çš„æ¨¡å—é‡å¤å †å è€Œæˆçš„ã€‚

ä»€ä¹ˆæ˜¯ Bottleneckï¼Ÿ ä½ å¯ä»¥æŠŠå®ƒçœ‹ä½œä¸€ä¸ªâ€œä¸‰æ˜æ²»â€ç»“æ„ï¼Œå®ƒåŒ…å«ä¸‰ä¸ªå·ç§¯å±‚ï¼š

- **1. 1x1 å·ç§¯ ï¼šå…ˆæŠŠé€šé“æ•°é™ä¸‹æ¥ï¼ˆé™ç»´ï¼‰ï¼Œå‡å°‘è®¡ç®—é‡ï¼ˆåƒæŠŠé¢å›¢å‹å®ï¼‰ã€‚**
- **2. 3x3 å·ç§¯ ï¼šåœ¨ä½ç»´ç©ºé—´è¿›è¡Œå¤„ç†ï¼Œæå–ç‰¹å¾ï¼ˆåƒåœ¨é¢å›¢ä¸Šåˆ»èŠ±ï¼‰ã€‚**
- **3. 1x1 å·ç§¯ ï¼šå†æŠŠé€šé“æ•°å‡ä¸Šå»ï¼ˆå‡ç»´ï¼‰ï¼Œæ¢å¤ç‰¹å¾ç»´åº¦ï¼ˆåƒæŠŠé¢å›¢å‘é…µå˜å¤§ï¼‰ã€‚**

- **3. è¾“å‡ºé˜¶æ®µ**


```py
(avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
(fc): Linear(in_features=2048, out_features=1000, bias=True)
```

- AdaptiveAvgPool2d (å¹³å‡æ± åŒ–) ï¼šä¸ç®¡å‰é¢å‡ºæ¥çš„å°ºå¯¸æ˜¯å¤šå°‘ï¼ˆè¿™é‡Œæ˜¯ 7x7ï¼‰ï¼Œå®ƒéƒ½æŠŠæ¯ä¸ªé€šé“çš„æ•°å€¼æ±‚å¹³å‡ï¼Œå‹ç¼©æˆ 1x1 çš„ä¸€ä¸ªç‚¹ã€‚
    - è¾“å…¥ï¼š2048 ä¸ªé€šé“ï¼Œæ¯ä¸ªé€šé“ 7x7ã€‚
    - è¾“å‡ºï¼š2048 ä¸ªæ•°å€¼ï¼ˆæ¯ä¸ªæ•°å€¼ä»£è¡¨è¯¥é€šé“çš„å¹³å‡ç‰¹å¾å¼ºåº¦ï¼‰ã€‚
- Linear (å…¨è¿æ¥å±‚/FC) ï¼šè¿™æ˜¯æœ€åçš„è£åˆ¤ã€‚
    - in_features=2048 ï¼šæ¥æ”¶è¿™ 2048 ä¸ªç‰¹å¾ã€‚
    - out_features=1000 ï¼šè¾“å‡º 1000 ä¸ªæ•°å€¼ã€‚
    - è¿™ 1000 ä¸ªæ•°å€¼åˆ†åˆ«å¯¹åº” ImageNet æ•°æ®é›†ä¸­çš„ 1000 ä¸ªç±»åˆ«ï¼ˆå¦‚çŒ«ã€ç‹—ã€é£æœºç­‰ï¼‰ã€‚æ•°å€¼æœ€å¤§çš„é‚£ä¸ªç±»åˆ«ï¼Œå°±æ˜¯ç½‘ç»œè®¤ä¸ºçš„é¢„æµ‹ç»“æœã€‚

**ä¿®æ”¹æ¨¡å‹ï¼š**

å¦‚æœæˆ‘ä»¬æƒ³è¦ä¿®æ”¹è¿™ä¸ªæ¨¡å‹çš„è¯ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡ç±»ä¼¼ `model.layer1[2].conv1` çš„æ–¹å¼å»è®¿é—®ä»¥åŠä¿®æ”¹å¯¹åº”çš„ç»“æ„å±‚ã€‚

### 3. å®Œæ•´çš„æ¨¡å‹è®­ç»ƒæµç¨‹

æœ¬èŠ‚æˆ‘ä»¬å°†ä¸²è”ä¸Šè¿°æ‰€æœ‰æ­¥éª¤ï¼Œå®Œæˆä¸€ä¸ªå®Œæ•´çš„æ¨¡å‹è®­ç»ƒæµç¨‹ã€‚

ä¸€ä¸ªæ¨¡å‹çš„è®­ç»ƒæ­¥éª¤å¯ä»¥åˆ†ä¸ºä»¥ä¸‹å‡ æ­¥ï¼š

- **1. å‰ç½®æ•°æ®å‡†å¤‡**ï¼šåŠ è½½æ¨¡å‹å’Œæ•°æ®é›†

- **2. å‰ç½®åŸºæœ¬å‡†å¤‡**ï¼šå®šä¹‰æŸå¤±å‡½æ•°ã€ä¼˜åŒ–å™¨ç­‰

- **3. å¼€å§‹è¿›è¡Œè®­ç»ƒå¾ªç¯**ï¼šå¾ªç¯å¯¹æ¨¡å‹è¿›è¡Œè®­ç»ƒï¼šåŒ…æ‹¬å‰å‘ä¼ æ’­ï¼ˆè®¡ç®—æ¨¡å‹è¾“å‡ºï¼‰ã€è®¡ç®—æŸå¤±å€¼ç­‰

- **4. åå‘ä¼ æ’­**ï¼šå¼€å§‹çœŸæ­£çš„æ¨¡å‹è®­ç»ƒï¼Œè®¡ç®—æ¢¯åº¦ã€æ›´æ–°æ¨¡å‹å‚æ•°ç­‰

- **5. æ¨¡å‹è¯„ä¼°**ï¼šåœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°æ¨¡å‹æ€§èƒ½

- **6. æ¨¡å‹ä¿å­˜**ï¼šå°†è®­ç»ƒå¥½çš„æ¨¡å‹ä¿å­˜èµ·æ¥ï¼Œæ–¹ä¾¿åç»­ä½¿ç”¨

- **7. æ¨¡å‹æ¨ç†**ï¼šä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹è¿›è¡Œé¢„æµ‹

é¦–å…ˆæˆ‘ä»¬è¿›è¡Œç¬¬ä¸€æ­¥ï¼šå‰ç½®æ•°æ®å‡†å¤‡ã€‚

#### 3.1. åŠ è½½æ¨¡å‹å’Œæ•°æ®é›†

æˆ‘ä»¬ä½¿ç”¨ä¸Šè¿°ç« èŠ‚ä¸­æˆ‘ä»¬è‡ªå·±æ­å»ºå¥½çš„ `CIFAR10CNN` ç¥ç»ç½‘ç»œè¿›è¡Œæ¨¡å‹è®­ç»ƒã€‚å› æ­¤å…ˆå‡†å¤‡å¥½æ¨¡å‹ä»¥åŠå¯¹åº”çš„ CIFAR10 æ•°æ®é›†ã€‚

```PY
# è®­ç»ƒæ•°æ®é›† å’Œ æµ‹è¯•æ•°æ®é›†
train_data = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform.ToTensor())
test_data = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform.ToTensor())


# æ¨¡å‹å®šä¹‰
class CIFAR10CNN(nn.Module):
    def __init__(self):
        super().__init__()
        self.model = nn.Sequential(
            nn.Conv2d(3, 32, 5, 1, 2),
            nn.MaxPool2d(2, 2),
            nn.Conv2d(32, 32, 5, 1, 2),
            nn.MaxPool2d(2, 2),
            nn.Conv2d(32, 64, 5, 1, 2),
            nn.MaxPool2d(2, 2),
            nn.Flatten(),
            nn.Linear(64 * 4 * 4, 10),
        )
    def forward(self, x):
        x = self.model(x)
        return x
```

è¿™é‡Œæˆ‘ä»¬ç®€åŒ–äº†ä¸€ä¸‹æ­å»ºç¥ç»ç½‘ç»œçš„è¿‡ç¨‹ï¼Œä½¿ç”¨ `nn.Sequential` æ¥æŠŠæ‰€æœ‰å±‚æŒ‰é¡ºåºä¸²èµ·æ¥ã€‚

#### 3.2. å®šä¹‰æŸå¤±å‡½æ•°ã€ä¼˜åŒ–å™¨ä»¥åŠä½¿ç”¨ GPU è¿›è¡Œè®­ç»ƒ

- **æŸå¤±å‡½æ•°**ï¼šæˆ‘ä»¬ä½¿ç”¨ `nn.CrossEntropyLoss` ä½œä¸ºæŸå¤±å‡½æ•°ï¼Œå®ƒé€‚ç”¨äºå¤šåˆ†ç±»ä»»åŠ¡ã€‚
- **ä¼˜åŒ–å™¨**ï¼šæˆ‘ä»¬ä½¿ç”¨ `torch.optim.SGD` ä½œä¸ºä¼˜åŒ–å™¨ï¼Œå­¦ä¹ ç‡è®¾ä¸º 1e-2ã€‚
- **GPU åŠ é€Ÿ**ï¼šå¦‚æœæœ‰ GPU å¯ç”¨ï¼Œæˆ‘ä»¬ä¼šå°†æ¨¡å‹å’Œæ•°æ®ç§»åŠ¨åˆ° GPU ä¸Šè¿›è¡ŒåŠ é€Ÿè®­ç»ƒã€‚

```python

# è®­ç»ƒæ¬¡æ•°
epoch = 20
# å½“å‰è®­ç»ƒçš„æ¬¡æ•°
current_train_step = 1
# æŸå¤±å‡½æ•°
loss_fn = nn.CrossEntropyLoss()

# ä¼˜åŒ–å™¨
optimizer = torch.optim.SGD(model.parameters(), lr=1e-2)

# æ£€æŸ¥æ˜¯å¦æœ‰ GPU å¯ç”¨
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)
```

> æ³¨æ„ï¼Œç”±äºç¬”è€…çš„ç”µè„‘æ˜¯ Aå¡ ï¼Œå› æ­¤ä¸èƒ½ä½¿ç”¨ cudaã€‚æˆ‘ä½¿ç”¨çš„æ˜¯ `torch_directml` æ¥è¿›è¡Œ GPU åŠ é€Ÿã€‚è¿™ä¸ªåº“å¯ä»¥åœ¨ Windows ä¸Šä½¿ç”¨ DirectML æ¥è¿›è¡Œ GPU åŠ é€Ÿã€‚ä½†æ˜¯è¿™ä¸ªåº“å¯¹ç‰ˆæœ¬è¦æ±‚æœ‰ç‚¹ä¸¥æ ¼ï¼Œéœ€è¦å¯¹ torch ä»¥åŠ torchvision è¿›è¡Œç‰ˆæœ¬é™çº§ã€‚

```toml
  "torch==2.4.1",
  "torch-directml>=0.2.5.dev240914",
  "torchvision==0.19.1",
```

ä»£ç å¦‚ä¸‹ï¼š

```py
import torch_directml
device = torch_directml.device()
model.to(device)
```

#### 3.3. å¼€å§‹è¿›è¡Œè®­ç»ƒå¾ªç¯ å’Œ åå‘ä¼ æ’­

æˆ‘ä»¬å¼€å§‹è¿›è¡Œè®­ç»ƒå¾ªç¯ã€‚åœ¨æ¯ä¸ª epoch ä¸­ï¼Œæˆ‘ä»¬ä¼šéå†è®­ç»ƒæ•°æ®é›†ï¼Œè¿›è¡Œå‰å‘ä¼ æ’­ã€è®¡ç®—æŸå¤±ã€åå‘ä¼ æ’­å’Œå‚æ•°æ›´æ–°ã€‚

```python
# è®­ç»ƒå¾ªç¯
for epoch in range(epoch):
  print(f"=============ç¬¬{epoch}è½®è®­ç»ƒå¼€å§‹=============")
  dataloader = DataLoader(train_data, batch_size=64)
  for batch in dataloader:
      images, labels = batch
      # å¯¹äºæ•°æ®é›†ï¼Œä¹Ÿè¦åˆ‡æ¢åˆ° GPU ä¸Š
      images, labels = images.to(device), labels.to(device)
      # å‰å‘ä¼ æ’­
      outputs = model(images)
      # è®¡ç®—æŸå¤±
      loss = loss_fn(outputs, labels)
      # æ¢¯åº¦æ¸…é›¶
      optimizer.zero_grad()
      # åå‘ä¼ æ’­
      loss.backward()
      # æ›´æ–°å‚æ•°
      optimizer.step()

      current_train_step += 1

      # æ‰“å°è®­ç»ƒä¿¡æ¯
      if current_train_step % 100 == 0:
        print(f"ç¬¬{current_train_step}æ¬¡è®­ç»ƒï¼ŒæŸå¤±ä¸º:{loss.item():.4f}")
        tensorboard.add_scalar("train_loss", loss.item(), current_train_step)
      current_train_step += 1
```

æŒ‰ç…§ä»¥ä¸Šæ­¥éª¤ï¼Œæˆ‘ä»¬å°†å¯¹æ¨¡å‹è¿›è¡Œ 20 è½®è®­ç»ƒã€‚è¿™é‡Œæˆ‘ä»¬å¯ä»¥å»æŸ¥çœ‹ tensorboard ä¸­çš„è®­ç»ƒæŸå¤±æ›²çº¿ã€‚æˆ‘ä»¬å¯ä»¥çœ‹åˆ°æœ€ç»ˆçš„æŸå¤±å€¼å·²ç»æ”¶æ•›åˆ°äº† 1 ä»¥ä¸‹ï¼Œè¯´æ˜æ¨¡å‹çš„è®­ç»ƒæ•ˆæœå·²åŸºæœ¬å®Œæˆã€‚

![è®­ç»ƒæŸå¤±æ›²çº¿](train_loss_line.png)

#### 3.4. æ¨¡å‹è¯„ä¼°

åœ¨è®­ç»ƒè¿‡ç¨‹åï¼Œæˆ‘ä»¬éœ€è¦è¯„ä¼°æ¨¡å‹åœ¨æµ‹è¯•é›†ä¸Šçš„æ€§èƒ½ï¼Œæ¥æŸ¥çœ‹æ¨¡å‹çš„è®­ç»ƒæ•ˆæœå’Œæ³›åŒ–èƒ½åŠ›ã€‚

åœ¨æµ‹è¯•è¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬éœ€è¦å…³é—­æ¢¯åº¦è®¡ç®—ï¼Œä»¥åŠ é€Ÿè¯„ä¼°è¿‡ç¨‹ï¼Œå†µä¸”è¿™ä¸ªæ—¶å€™æˆ‘ä»¬ä¹Ÿä¸éœ€è¦æ¢¯åº¦äº†ã€‚

```python
# è¯„ä¼°æ¨¡å‹
model.eval()
with torch.no_grad():
    test_dataloader = DataLoader(test_data, batch_size=64)
    # è®¡ç®—å‡†ç¡®
    total_correct = 0
    for batch in test_dataloader:
        images, labels = batch
        images, labels = images.to(device), labels.to(device)
        outputs = model(images)
        # è¡¨ç¤ºç»´åº¦æ˜¯ä»å·¦åˆ°å³çš„
        predicted = outputs.argmax(dim=1)
        total_correct += (predicted == labels).sum().item()
    print(
      f"=============ç¬¬{epoch + 1}è½®æµ‹è¯•ç»“æŸï¼Œå‡†ç¡®ç‡ä¸º{total_accuracy / len(test_dataset):.4f}============="
    )
    tensorboard.add_scalar(
        "test_accuracy",
        total_accuracy / len(test_dataset),
        epoch + 1,
    )
```

è¿™é‡Œæ™®åŠä¸€ä¸‹ï¼Œ`argmax` å‡½æ•°çš„ä½œç”¨æ˜¯è¿”å›å¼ é‡ä¸­æ¯ä¸ªç»´åº¦ä¸Šçš„æœ€å¤§å€¼çš„ç´¢å¼•ã€‚åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨ `dim=1` è¡¨ç¤ºåœ¨ç¬¬äºŒä¸ªç»´åº¦ä¸Šè¿›è¡Œæœ€å¤§å€¼ç´¢å¼•çš„è®¡ç®—ã€‚è¿™æ˜¯å› ä¸ºæˆ‘ä»¬çš„æ¨¡å‹è¾“å‡ºæ˜¯ä¸€ä¸ª 10 ç»´çš„å‘é‡ï¼Œæ¯ä¸ªç»´åº¦å¯¹åº”ä¸€ä¸ªç±»åˆ«çš„é¢„æµ‹æ¦‚ç‡ã€‚æˆ‘ä»¬ä½¿ç”¨ `argmax` æ¥è·å–æ¯ä¸ªæ ·æœ¬çš„é¢„æµ‹ç±»åˆ«ï¼Œå³æ¦‚ç‡æœ€é«˜çš„ç±»åˆ«ã€‚

ä¸¾ä¸ªä¾‹å­ï¼š

```bash
digits = [[0.1,0.2,0.3],
          [0.1,0.3,0.2],
          [0.3,0.1,0.2]]

digits = torch.tensor(digits)
# è¡¨ç¤ºåœ¨ç¬¬äºŒä¸ªç»´åº¦ä¸Šè¿›è¡Œæœ€å¤§å€¼ç´¢å¼•çš„è®¡ç®—
predicted = digits.argmax(dim=1)
print(predicted) 
# tensor([2, 1, 0])
```

å¦‚æœæˆ‘ä»¬æŠŠ `dim=0` ï¼Œè¡¨ç¤ºåœ¨ç¬¬ä¸€ä¸ªç»´åº¦ä¸Šè¿›è¡Œæœ€å¤§å€¼ç´¢å¼•çš„è®¡ç®—ã€‚ï¼ˆä»ä¸Šåˆ°ä¸‹ï¼‰

```bash
predicted = digits.argmax(dim=0)
print(predicted) 
# tensor([2, 1, 0])
```

æˆ‘ä»¬åœ¨ tensorboard ä¸­ä¹Ÿå¯ä»¥æŸ¥çœ‹æµ‹è¯•å‡†ç¡®ç‡çš„æ›²çº¿ã€‚å¯ä»¥çœ‹åˆ°ï¼Œæœ€ç»ˆæµ‹è¯•å‡†ç¡®ç‡ä» 0.27 åˆ°äº† 0.63 ï¼Œè¯´æ˜æ¨¡å‹çš„è®­ç»ƒæ•ˆæœè¿˜æ˜¯æ¯”è¾ƒå¥½çš„ã€‚

![è®­ç»ƒå‡†ç¡®ç‡æ›²çº¿](train_accuracy_line.png)

#### 3.5. æ¨¡å‹ä¿å­˜

æ¨¡å‹è®­ç»ƒå®Œæˆåï¼Œæˆ‘ä»¬éœ€è¦ä¿å­˜æ¨¡å‹ï¼Œä»¥ä¾¿åç»­ä½¿ç”¨ã€‚

```python
# ä¿å­˜æ¨¡å‹
if epoch % 10 == 0:
    if not os.path.exists("./train_models"):
        os.makedirs("./train_models")
    torch.save(model.state_dict(), f"./train_models/cifar10_cnn_{epoch}.pth")
```

#### 3.6. æ¨¡å‹æ¨ç†

æˆ‘ä»¬ç»ƒå¥½çš„ä»™ä¸¹å·²ç»å‡ºç‚‰äº†ï¼Œå¿«ç”¨å®ƒæ¥é¢„æµ‹ä¸€ä¸‹å§ï¼

æ¯”å¦‚è¯´ï¼Œè¿™é‡Œæˆ‘éšä¾¿æ‰¾äº†ä¸€å¼ èˆ¹çš„å›¾ç‰‡ã€‚

ï¼[Ship](ship.png)

é¦–å…ˆæˆ‘ä»¬éœ€è¦åŠ è½½æ¨¡å‹ã€‚ç”±äºåœ¨ä¸Šä¸€æ­¥ä¸­ï¼Œæˆ‘ä»¬é€šè¿‡ `model.state_dict()` ä¿å­˜äº†æ¨¡å‹çš„å‚æ•°ï¼Œæ‰€ä»¥æˆ‘ä»¬å¯ä»¥é€šè¿‡ `model.load_state_dict()` æ¥åŠ è½½æ¨¡å‹çš„å‚æ•°ã€‚

åœ¨PyTorchä¸­ï¼Œæ¨¡å‹ä¿å­˜æœ‰ä¸¤ç§æ–¹å¼ï¼šç›´æ¥ä¿å­˜ `model` å’Œ åªä¿å­˜æ¨¡å‹å‚æ•° `model.state_dict()` 

ä¸»è¦åŒºåˆ«æ€»ç»“å¦‚ä¸‹ï¼š

| ç‰¹æ€§ | `model` ä¿å­˜ | `model.state_dict()` ä¿å­˜ |
|------|-------------|-------------------------|
| ä¿å­˜å†…å®¹ | å®Œæ•´æ¨¡å‹å¯¹è±¡ | ä»…æ¨¡å‹å‚æ•° |
| æ–‡ä»¶å¤§å° | è¾ƒå¤§ | è¾ƒå° |
| åŠ è½½çµæ´»æ€§ | ä½ | é«˜ |
| ç‰ˆæœ¬å…¼å®¹æ€§ | è¾ƒå·® | è¾ƒå¥½ |
| æ¨èç¨‹åº¦ | ä¸æ¨è | æ¨è |

- **ä½¿ç”¨ `model` ä¿å­˜**ï¼šå¿«é€ŸåŸå‹å¼€å‘ï¼Œä¸´æ—¶ä¿å­˜ï¼Œå¯¹ç‰ˆæœ¬å…¼å®¹æ€§è¦æ±‚ä¸é«˜çš„åœºæ™¯
- **ä½¿ç”¨ `model.state_dict()` ä¿å­˜**ï¼šæ­£å¼é¡¹ç›®ï¼Œéœ€è¦é•¿æœŸç»´æŠ¤çš„æ¨¡å‹ï¼Œå¯¹ç‰ˆæœ¬å…¼å®¹æ€§æœ‰è¦æ±‚çš„åœºæ™¯

åœ¨å®é™…åº”ç”¨ä¸­ï¼Œå‡ ä¹æ‰€æœ‰çš„ç”Ÿäº§ç¯å¢ƒå’Œå¼€æºé¡¹ç›®éƒ½é‡‡ç”¨ `model.state_dict()` çš„æ–¹å¼ä¿å­˜æ¨¡å‹ï¼Œå› ä¸ºå®ƒæä¾›äº†æ›´å¥½çš„çµæ´»æ€§å’Œå…¼å®¹æ€§ã€‚


```python
class CIFAR10CNN(nn.Module):
    def __init__(self):
        super().__init__()
        self.model = nn.Sequential(
            nn.Conv2d(3, 32, 5, 1, 2),
            nn.MaxPool2d(2, 2),
            nn.Conv2d(32, 32, 5, 1, 2),
            nn.MaxPool2d(2, 2),
            nn.Conv2d(32, 64, 5, 1, 2),
            nn.MaxPool2d(2, 2),
            nn.Flatten(),
            nn.Linear(64 * 4 * 4, 10),
        )

    def forward(self, x):
        x = self.model(x)
        return x


if __name__ == "__main__":
    model = CIFAR10CNN()
    state_dict = torch.load("./train_models/cifar10_cnn_20.pth")
    model.load_state_dict(state_dict)
    # ...
```

åŠ è½½å®Œæ¨¡å‹å‚æ•°åï¼Œæˆ‘ä»¬å°±å¯ä»¥ä½¿ç”¨æ¨¡å‹è¿›è¡Œæ¨ç†äº†ã€‚å…ˆåŠ è½½å’Œé¢„å¤„ç†æˆ‘ä»¬å‡†å¤‡å¥½çš„å›¾ç‰‡ï¼š

```python
cat_img = Image.open("./ship.jpg")
# å¯¹å›¾ç‰‡è¿›è¡Œé¢„å¤„ç†
trans = transforms.Compose(
    [
        transforms.Resize((32, 32)),
        transforms.ToTensor(),
    ]
)
cat_tensor = trans(cat_img)
# å¢åŠ ä¸€ä¸ª batch ç»´åº¦
cat_tensor = cat_tensor.unsqueeze(0)
# ï¼ˆ1ï¼Œ3ï¼Œ32ï¼Œ32ï¼‰
print(cat_tensor.shape)
```

æœ€åæ¥è¿›è¡Œæ¨ç†ï¼š

```python
test_dataset = datasets.CIFAR10(
  root="./dataset", train=False, download=True, transform=transforms.ToTensor()
)
labels = test_dataset.classes
# å‰å‘ä¼ æ’­
with torch.no_grad():
  model.eval()
  outputs = model(cat_tensor)
  predicted = outputs.argmax(dim=1)
  print(labels[predicted.item()])
  # ship
```

è¿™å°±æ˜¯æ•´ä¸ªçš„æ¨¡å‹æ¨ç†éªŒè¯è¿‡ç¨‹ã€‚ç”±äºæˆ‘ä»¬è®­ç»ƒçš„æ¨¡å‹å‡†ç¡®ç‡åªæœ‰ 63% ï¼Œæ‰€ä»¥æ¨ç†ç»“æœå¯èƒ½ä¼šæœ‰è¯¯å·®ã€‚å› æ­¤è¿™é‡Œå¦‚æœé€‰æ‹©äº†å°çŒ«ã€å°ç‹—ç­‰å›¾ç‰‡ï¼Œæ¨¡å‹å¯èƒ½ä¼šé”™è¯¯åœ°å°†å…¶åˆ†ç±»ã€‚